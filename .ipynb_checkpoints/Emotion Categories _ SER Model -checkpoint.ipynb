{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234d088a",
   "metadata": {},
   "source": [
    "Dataset retrieved from: https://zenodo.org/record/1188976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc034fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd838b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288c66a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "import librosa                    # Python package for music and audio analysis\n",
    "import librosa.display            # Allows you to display audio files \n",
    "import os                         # The OS module in Python provides a way of \n",
    "                                  # using operating system dependent functionality.\n",
    "import scipy.io.wavfile           # Open a WAV files\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import numpy as np                # Used for working with arrays\n",
    "import fastai                     \n",
    "import glob                       # Used to return all file paths that match a specific \n",
    "                                  # pattern\n",
    "\n",
    "import sounddevice as sd\n",
    "\n",
    "\n",
    "# Import fast AI stuff\n",
    "# from fastai import *                                 \n",
    "# from fastai.vision.all import *\n",
    "# from fastai.vision.data import ImageDataLoaders\n",
    "# from fastai.tabular.all import *\n",
    "# from fastai.text.all import *\n",
    "# from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867683ea",
   "metadata": {},
   "source": [
    "# DOWNLOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\")\n",
    "# use kaggle credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099568bd",
   "metadata": {},
   "source": [
    "# CREATE NEEDED DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32392244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ./ravdess-emotional-speech-audio/audio_speech_actors_01-24: No such file or directory\n",
      "mkdir: ./output: File exists\n",
      "mkdir: ./output/live_images: File exists\n",
      "mkdir: ./models: File exists\n"
     ]
    }
   ],
   "source": [
    "!rm -r \"./ravdess-emotional-speech-audio/audio_speech_actors_01-24\"\n",
    "\n",
    "!mkdir './output'\n",
    "!mkdir './output/live_images'\n",
    "\n",
    "# !mkdir './DATASET'\n",
    "# !mkdir './DATASET/angry'\n",
    "# !mkdir './DATASET/calm'\n",
    "# !mkdir './DATASET/disgust'\n",
    "# !mkdir './DATASET/fearful'\n",
    "# !mkdir './DATASET/neutral'\n",
    "# !mkdir './DATASET/sad'\n",
    "# !mkdir './DATASET/happy'\n",
    "# !mkdir './DATASET/surprised'\n",
    "\n",
    "!mkdir './models'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98b935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir './Categorical_Dataset'          \n",
    "!mkdir './Categorical_Dataset/positive' # happy, surprised\n",
    "!mkdir './Categorical_Dataset/negative' # angry, sad, disgusted, fearful\n",
    "!mkdir './Categorical_Dataset/neutral'  # neutral, calm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c319e5",
   "metadata": {},
   "source": [
    "# DEFINING THE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccc25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FOLDER = \"./ravdess-emotional-speech-audio/*\"\n",
    "DATASET = \"./Categorical_Dataset/\"\n",
    "\n",
    "\n",
    "paths = [audioFile for actor in glob.glob(AUDIO_FOLDER) for audioFile in glob.glob(actor +'/*')]\n",
    "\n",
    "result = [paths[i:i+10] for i in range(0, len(paths), 10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1a2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotions\n",
    "dicts = {\n",
    "    '01' : 'neutral', \n",
    "    '02' : 'calm', \n",
    "    '03' : 'happy', \n",
    "    '04' : 'sad', \n",
    "    '05' : 'angry', \n",
    "    '06' : 'fearful', \n",
    "    '07' : 'disgust', \n",
    "    '08' : 'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9041724",
   "metadata": {},
   "source": [
    "# RUN THIS CODE TO CLEAR THE DATASET FOLDER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d129268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the test1 and train1 folders:\n",
    "directories = [DATASET] # specify the path to the directory\n",
    "\n",
    "for directory in directories:\n",
    "    for foldername in os.listdir(directory):\n",
    "        folderpath = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folderpath):\n",
    "            for filename in os.listdir(folderpath):\n",
    "                filepath = os.path.join(folderpath, filename)\n",
    "                if os.path.isfile(filepath):\n",
    "                    os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee614bf",
   "metadata": {},
   "source": [
    "# CONVERT ALL AUDIO FILES TO MELSPECTROGRAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788915e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b108079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_melspectrogram(audioPath, savePath):\n",
    "\n",
    "    # Load audio file and visualize its waveform (using librosa)\n",
    "    # The `librosa.load()` function takes two arguments: the path to the audio file and the sample rate.\n",
    "    # The sample rate is the number of samples per second in the audio file.\n",
    "    x, sr = librosa.load(audioPath, sr=44100)\n",
    "\n",
    "    # Trim the audio file to remove silence at the beginning and end.\n",
    "    # The `librosa.effects.trim()` function takes two arguments: the audio signal and the threshold.\n",
    "    # The threshold is the minimum amplitude that is considered to be non-silence.\n",
    "    xt,_=librosa.effects.trim(x)                         \n",
    "\n",
    "    x=xt\n",
    "\n",
    "    # Plot the spectrogram.\n",
    "    # The `librosa.stft()` function computes the short-time Fourier transform of the audio signal.\n",
    "    # The `librosa.amplitude_to_db()` function converts the amplitude of the spectrogram to decibels.\n",
    "    X = librosa.stft(x)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "    # Apply log transformation on the loaded audio signals\n",
    "    # The `librosa.display.specshow()` function plots the spectrogram.\n",
    "    # The `sr` argument specifies the sample rate of the audio signal.\n",
    "    # The `x_axis` argument specifies the axis along which the time is displayed.\n",
    "    # The `y_axis` argument specifies the axis along which the frequency is displayed.\n",
    "    librosa.display.specshow(Xdb, sr=sr, vmin=-60, vmax=60,x_axis='time', y_axis='log',cmap='magma', ax=None)\n",
    "\n",
    "    #plt.colorbar()\n",
    "    \n",
    "    # Remove the axis\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Save the figure.\n",
    "    # The `plt.savefig()` function saves the figure to a file.\n",
    "    # The `savePath` argument specifies the path to the file.\n",
    "    plt.savefig(savePath)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64830742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_audio_to_melspectrogram(result[0][0],\"./output/sup\")\n",
    "# convert_audio_to_melspectrogram(result[0][1],\"./output/sup\")\n",
    "# convert_audio_to_melspectrogram(result[0][2],\"./output/sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37daafff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  2.95it/s, 1/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  3.25it/s, 2/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  3.13it/s, 3/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  3.23it/s, 4/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:02<00:00,  3.58it/s, 5/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:02<00:00,  3.53it/s, 6/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  2.90it/s, 7/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  3.03it/s, 8/144]\n",
      "100%|████████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s, 9/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.68it/s, 10/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.65it/s, 11/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.94it/s, 12/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.88it/s, 13/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.34it/s, 14/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.64it/s, 15/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.66it/s, 16/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.71it/s, 17/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.61it/s, 18/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.23it/s, 19/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.30it/s, 20/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.97it/s, 21/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.72it/s, 22/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.99it/s, 23/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.05it/s, 24/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.27it/s, 25/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:04<00:00,  2.43it/s, 26/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.69it/s, 27/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.30it/s, 28/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.04it/s, 29/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.20it/s, 30/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.65it/s, 31/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.57it/s, 32/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.70it/s, 33/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.77it/s, 34/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.70it/s, 35/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.85it/s, 36/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.93it/s, 37/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.90it/s, 38/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s, 39/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.60it/s, 40/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.92it/s, 41/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s, 42/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s, 43/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.73it/s, 44/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.68it/s, 45/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.90it/s, 46/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.86it/s, 47/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.79it/s, 48/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.73it/s, 49/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.84it/s, 50/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.45it/s, 51/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.67it/s, 52/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.47it/s, 53/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  4.18it/s, 54/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.73it/s, 55/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.90it/s, 56/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.94it/s, 57/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.82it/s, 58/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.85it/s, 59/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.91it/s, 60/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.60it/s, 61/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.43it/s, 62/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.85it/s, 63/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.53it/s, 64/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.78it/s, 65/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.61it/s, 66/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.79it/s, 67/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.86it/s, 68/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.81it/s, 69/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.70it/s, 70/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.61it/s, 71/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.99it/s, 72/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.02it/s, 73/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.17it/s, 74/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.13it/s, 75/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.13it/s, 76/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.84it/s, 77/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.27it/s, 78/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.05it/s, 79/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.91it/s, 80/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.13it/s, 81/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.88it/s, 82/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.20it/s, 83/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s, 84/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.77it/s, 85/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.51it/s, 86/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  4.31it/s, 87/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.83it/s, 88/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  4.00it/s, 89/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.54it/s, 90/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.46it/s, 91/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.43it/s, 92/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.09it/s, 93/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.42it/s, 94/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.35it/s, 95/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.43it/s, 96/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:02<00:00,  3.57it/s, 97/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.25it/s, 98/144]\n",
      "100%|███████████████████████████████████| 10/10 [00:03<00:00,  3.33it/s, 99/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.30it/s, 100/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.50it/s, 101/144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.16it/s, 102/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.82it/s, 103/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.20it/s, 104/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.77it/s, 105/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.44it/s, 106/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.67it/s, 107/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.40it/s, 108/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.38it/s, 109/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.07it/s, 110/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.21it/s, 111/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.18it/s, 112/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.20it/s, 113/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.14it/s, 114/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.98it/s, 115/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.92it/s, 116/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:04<00:00,  2.35it/s, 117/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.60it/s, 118/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.89it/s, 119/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.91it/s, 120/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.83it/s, 121/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.06it/s, 122/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:04<00:00,  2.32it/s, 123/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.89it/s, 124/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.57it/s, 125/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.72it/s, 126/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.85it/s, 127/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.09it/s, 128/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.67it/s, 129/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.02it/s, 130/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.86it/s, 131/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.85it/s, 132/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.45it/s, 133/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.75it/s, 134/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.51it/s, 135/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:02<00:00,  3.61it/s, 136/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.91it/s, 137/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  3.04it/s, 138/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.58it/s, 139/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.62it/s, 140/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.68it/s, 141/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.56it/s, 142/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.68it/s, 143/144]\n",
      "100%|██████████████████████████████████| 10/10 [00:03<00:00,  2.67it/s, 144/144]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the audio files to melspectrograms.\n",
    "counts = {}\n",
    "fileLoc=1\n",
    "for path in result:\n",
    "    files = tqdm(path)\n",
    "    for audio_file_path in files:\n",
    "        files.set_postfix_str(f\"{fileLoc}/{len(result)}\")\n",
    "        \n",
    "        em = audio_file_path[-18:-16]\n",
    "        \n",
    "        emotion = ''\n",
    "        \n",
    "        if em in ('01','02'):\n",
    "            emotion = f'neutral'\n",
    "        if em in ('03','08'):\n",
    "            emotion = f'positive'\n",
    "        if em in ('04','05','06','07'):\n",
    "            emotion = f'negative'\n",
    "        \n",
    "        count = counts.get(emotion, 1)\n",
    "        \n",
    "        # split up test and train data\n",
    "        p = os.path.join(f\"{DATASET}{emotion}\", f\"{emotion}{str(count).zfill(6)}_({dict[em]}).jpg\")\n",
    "        \n",
    "        \n",
    "        counts[emotion] = count + 1\n",
    "        \n",
    "        convert_audio_to_melspectrogram(audio_file_path, p)\n",
    "    fileLoc+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd262f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "fs=44100\n",
    "seconds=3\n",
    "dtype = 'int16'\n",
    "mic = int(input(f'Of the following list of devices, select which one to use as your microphone:\\n{sd.query_devices()}\\n>>>'))\n",
    "count = 1\n",
    "\n",
    "while true:\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    \n",
    "    checkEmotion(count,mic, fs, seconds, dtype)\n",
    "    \n",
    "    cont = input(\"\\nContinue? (Y/N): \")\n",
    "    \n",
    "    if cont == 'Y' or cont == 'y':\n",
    "        count+=1\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b0344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f81527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6493d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''loss_functions = [CrossEntropyLossFlat(), LabelSmoothingCrossEntropy(),\n",
    "                  FocalLossFlat()]\n",
    "loss_functions1 = [\"CrossEntropyLossFlat\", \"LabelSmoothingCrossEntropy\",\n",
    "                  \"FocalLossFlat\"]\n",
    "train_size = [0.2, 0.4, 0.6]\n",
    "\n",
    "for LF in range(0,3):\n",
    "    for TS in range(0,3):\n",
    "        print(f\"___________{loss_functions1[LF]} ... {train_size[TS]}___________\")\n",
    "        dls = ImageDataLoaders.from_folder(train_path, valid_pct=train_size[TS], seed=5, num_workers=0)\n",
    "        print(f\"validation: {len(dls.valid_ds.items[:])}  |  training set: {len(dls.train_ds.items[:])}\")\n",
    "\n",
    "        learn = vision_learner(dls, models.resnet34, loss_func=loss_functions[LF], metrics=accuracy)\n",
    "        lr_min, lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))\n",
    "        print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")\n",
    "\n",
    "        learn.fit(10, float(f\"{lr_steep:.2e}\"))\n",
    "        #interp = ClassificationInterpretation.from_learner(learn)\n",
    "        #losses,idxs = interp.top_losses()\n",
    "        #len(dls.valid_ds)==len(losses)==len(idxs)\n",
    "\n",
    "        #interp.plot_confusion_matrix(figsize=(8,8), dpi=90)\n",
    "\n",
    "        #interp.plot_top_losses(2, figsize=(10,11))\n",
    "        \n",
    "        print(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1c051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d832f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59833a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204665bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1379d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path('./DATASET').with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047816c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = list(data_dir.glob('angry/*'))\n",
    "PIL.Image.open(str(anger[0]))\n",
    "PIL.Image.open(str(anger[1]))\n",
    "\n",
    "calm = list(data_dir.glob('calm/*'))\n",
    "PIL.Image.open(str(calm[0]))\n",
    "PIL.Image.open(str(calm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 240\n",
    "img_width = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7515319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58923e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56356651",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19434a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a906337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df52b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c07dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(val_ds)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = []\n",
    "for images, labels in val_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae317de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fight overfitting by using data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bb02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc958c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c6310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilizing Dropout\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da74d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca42f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(val_ds)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = []\n",
    "for images, labels in val_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b757c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = './DATASET/angry/angry000001.jpg'\n",
    "#file_path = tf.keras.utils.get_file('thingo', origin=location)\n",
    "\n",
    "#img = pathlib.Path('./DATASET/angry/angry000001.jpg')\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "   location, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "\n",
    "\n",
    "sorted_predictions = np.argsort(score)[::-1]\n",
    "\n",
    "# Take the top five predictions.\n",
    "top_predictions = sorted_predictions[:5]\n",
    "\n",
    "# Print the top five predictions.\n",
    "for i in range(len(top_predictions)):\n",
    "    print(\n",
    "        \"The image most likely belongs to {} with a {:.4f} percent confidence.\"\n",
    "        .format(class_names[top_predictions[i]], 100 * score[top_predictions[i]])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
