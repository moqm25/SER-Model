{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234d088a",
   "metadata": {},
   "source": [
    "Dataset retrieved from: https://zenodo.org/record/1188976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0b84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc034fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce31fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a21193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd838b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288c66a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt   # plotting\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "import librosa                    # Python package for music and audio analysis\n",
    "import librosa.display            # Allows you to display audio files \n",
    "import os                         # The OS module in Python provides a way of \n",
    "                                  # using operating system dependent functionality.\n",
    "import scipy.io.wavfile           # Open a WAV files\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import numpy as np                # Used for working with arrays\n",
    "import fastai                     \n",
    "import glob                       # Used to return all file paths that match a specific \n",
    "                                  # pattern\n",
    "\n",
    "import sounddevice as sd\n",
    "\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Import fast AI stuff\n",
    "# from fastai import *                                 \n",
    "# from fastai.vision.all import *\n",
    "# from fastai.vision.data import ImageDataLoaders\n",
    "# from fastai.tabular.all import *\n",
    "# from fastai.text.all import *\n",
    "# from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867683ea",
   "metadata": {},
   "source": [
    "# DOWNLOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6186f4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: moiezqamar\n",
      "Your Kaggle Key: ········\n",
      "Downloading ravdess-emotional-speech-audio.zip to ./ravdess-emotional-speech-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 429M/429M [00:44<00:00, 10.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RAVDESS Emotional Speed audio Dataset\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\")\n",
    "# use kaggle credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e908e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: moiezqamar\n",
      "Your Kaggle Key: ········\n",
      "Downloading ravdess-emotional-song-audio.zip to ./ravdess-emotional-song-audio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 456M/456M [00:46<00:00, 10.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# RAVDESS Emotional Song audio Dataset\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-song-audio\")\n",
    "# use kaggle credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9b5d933",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./cremad\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# CREMA-D Dataset\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/ejlok1/cremad\")\n",
    "# use kaggle credentials\n",
    "# information about this dataset: https://github.com/CheyneyComputerScience/CREMA-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb79ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotions\n",
    "emotion_map = {\n",
    "    '01' : 'neutral', \n",
    "    '02' : 'calm', \n",
    "    '03' : 'happy', \n",
    "    '04' : 'sad', \n",
    "    '05' : 'angry', \n",
    "    '06' : 'fearful', \n",
    "    '07' : 'disgust', \n",
    "    '08' : 'surprised',\n",
    "    'NEU': '01',\n",
    "    'HAP': '03',\n",
    "    'SAD': '04',\n",
    "    'ANG': '05',\n",
    "    'FEA': '06',\n",
    "    'DIS': '07'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099568bd",
   "metadata": {},
   "source": [
    "# CREATE NEEDED DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32392244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ./output: File exists\n",
      "mkdir: ./output/live_images: File exists\n",
      "mkdir: ./models: File exists\n"
     ]
    }
   ],
   "source": [
    "!rm -r \"./ravdess-emotional-speech-audio/audio_speech_actors_01-24\"\n",
    "!rm -r \"./ravdess-emotional-song-audio/audio_song_actors_01-24\"\n",
    "\n",
    "\n",
    "!mkdir './output'\n",
    "!mkdir './output/live_images'\n",
    "\n",
    "!mkdir './Categorical_Dataset'          \n",
    "!mkdir './Categorical_Dataset/positive' # happy, surprised\n",
    "!mkdir './Categorical_Dataset/negative' # angry, sad, disgusted, fearful\n",
    "!mkdir './Categorical_Dataset/neutral'  # neutral, calm\n",
    "\n",
    "# !mkdir './DATASET'\n",
    "# !mkdir './DATASET/angry'\n",
    "# !mkdir './DATASET/calm'\n",
    "# !mkdir './DATASET/disgust'\n",
    "# !mkdir './DATASET/fearful'\n",
    "# !mkdir './DATASET/neutral'\n",
    "# !mkdir './DATASET/sad'\n",
    "# !mkdir './DATASET/happy'\n",
    "# !mkdir './DATASET/surprised'\n",
    "\n",
    "!mkdir './models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c319e5",
   "metadata": {},
   "source": [
    "# DEFINING THE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fccc25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FOLDER1 = \"./ravdess-emotional-speech-audio/*\"\n",
    "AUDIO_FOLDER2 = \"./ravdess-emotional-song-audio/*\"\n",
    "AUDIO_FOLDER3 = \"./cremad/*\"\n",
    "\n",
    "\n",
    "DATASET = \"./Categorical_Dataset/\"\n",
    "\n",
    "\n",
    "paths = [audioFile for actor in glob.glob(AUDIO_FOLDER1) for audioFile in glob.glob(actor +'/*')] + [audioFile for actor in glob.glob(AUDIO_FOLDER2) for audioFile in glob.glob(actor +'/*')] + [audioFile for actor in glob.glob(AUDIO_FOLDER3) for audioFile in glob.glob(actor +'/*')]\n",
    "\n",
    "result = [paths[i:i+51] for i in range(0, len(paths), 51)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75b58d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9894\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "print(len(paths))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9041724",
   "metadata": {},
   "source": [
    "# RUN THIS CODE TO CLEAR THE DATASET FOLDER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d129268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the test1 and train1 folders:\n",
    "directories = [DATASET] # specify the path to the directory\n",
    "\n",
    "for directory in directories:\n",
    "    for foldername in os.listdir(directory):\n",
    "        folderpath = os.path.join(directory, foldername)\n",
    "        if os.path.isdir(folderpath):\n",
    "            for filename in os.listdir(folderpath):\n",
    "                filepath = os.path.join(folderpath, filename)\n",
    "                if os.path.isfile(filepath):\n",
    "                    os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee614bf",
   "metadata": {},
   "source": [
    "# CONVERT ALL AUDIO FILES TO MELSPECTROGRAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b108079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_to_melspectrogram(audioPath, savePath):\n",
    "\n",
    "    # Load audio file and visualize its waveform (using librosa)\n",
    "    # The `librosa.load()` function takes two arguments: the path to the audio file and the sample rate.\n",
    "    # The sample rate is the number of samples per second in the audio file.\n",
    "    x, sr = librosa.load(audioPath, sr=44100)\n",
    "\n",
    "    # Trim the audio file to remove silence at the beginning and end.\n",
    "    # The `librosa.effects.trim()` function takes two arguments: the audio signal and the threshold.\n",
    "    # The threshold is the minimum amplitude that is considered to be non-silence.\n",
    "    xt,_=librosa.effects.trim(x)                         \n",
    "\n",
    "    x=xt\n",
    "\n",
    "    # Plot the spectrogram.\n",
    "    # The `librosa.stft()` function computes the short-time Fourier transform of the audio signal.\n",
    "    # The `librosa.amplitude_to_db()` function converts the amplitude of the spectrogram to decibels.\n",
    "    X = librosa.stft(x)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "    # Apply log transformation on the loaded audio signals\n",
    "    # The `librosa.display.specshow()` function plots the spectrogram.\n",
    "    # The `sr` argument specifies the sample rate of the audio signal.\n",
    "    # The `x_axis` argument specifies the axis along which the time is displayed.\n",
    "    # The `y_axis` argument specifies the axis along which the frequency is displayed.\n",
    "    librosa.display.specshow(Xdb, sr=sr, vmin=-60, vmax=60,x_axis='time', y_axis='log',cmap='magma', ax=None)\n",
    "\n",
    "    #plt.colorbar()\n",
    "    \n",
    "    # Remove the axis\n",
    "    plt.gca().get_xaxis().set_visible(False)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Save the figure.\n",
    "    # The `plt.savefig()` function saves the figure to a file.\n",
    "    # The `savePath` argument specifies the path to the file.\n",
    "    plt.savefig(savePath)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64830742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_audio_to_melspectrogram(result[0][0],\"./output/sup\")\n",
    "# convert_audio_to_melspectrogram(result[0][1],\"./output/sup\")\n",
    "# convert_audio_to_melspectrogram(result[0][2],\"./output/sup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37daafff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 51/51 [00:15<00:00,  3.37it/s, 1/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:16<00:00,  3.09it/s, 2/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:15<00:00,  3.34it/s, 3/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:14<00:00,  3.44it/s, 4/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:15<00:00,  3.25it/s, 5/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:16<00:00,  3.07it/s, 6/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:19<00:00,  2.62it/s, 7/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:17<00:00,  2.86it/s, 8/194]\n",
      "100%|████████████████████████████████████| 51/51 [00:18<00:00,  2.71it/s, 9/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:17<00:00,  2.96it/s, 10/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.29it/s, 11/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:16<00:00,  3.00it/s, 12/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.49it/s, 13/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.83it/s, 14/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:16<00:00,  3.01it/s, 15/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:17<00:00,  2.97it/s, 16/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.43it/s, 17/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.60it/s, 18/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.37it/s, 19/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.30it/s, 20/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.48it/s, 21/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.24it/s, 22/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:17<00:00,  2.93it/s, 23/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.81it/s, 24/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:17<00:00,  2.85it/s, 25/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:17<00:00,  2.91it/s, 26/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.42it/s, 27/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.79it/s, 28/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:19<00:00,  2.61it/s, 29/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:20<00:00,  2.50it/s, 30/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.81it/s, 31/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:20<00:00,  2.52it/s, 32/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:21<00:00,  2.36it/s, 33/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:23<00:00,  2.14it/s, 34/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.75it/s, 35/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:21<00:00,  2.38it/s, 36/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:19<00:00,  2.63it/s, 37/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:21<00:00,  2.36it/s, 38/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.69it/s, 39/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:20<00:00,  2.52it/s, 40/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:19<00:00,  2.65it/s, 41/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:19<00:00,  2.67it/s, 42/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:16<00:00,  3.08it/s, 43/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:21<00:00,  2.43it/s, 44/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:20<00:00,  2.51it/s, 45/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:20<00:00,  2.43it/s, 46/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:18<00:00,  2.74it/s, 47/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:21<00:00,  2.34it/s, 48/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.49it/s, 49/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.49it/s, 50/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.62it/s, 51/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.49it/s, 52/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.60it/s, 53/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.50it/s, 54/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:13<00:00,  3.64it/s, 55/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:13<00:00,  3.69it/s, 56/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:13<00:00,  3.71it/s, 57/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.45it/s, 58/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.32it/s, 59/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.25it/s, 60/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.48it/s, 61/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:13<00:00,  3.65it/s, 62/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.19it/s, 63/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.19it/s, 64/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.53it/s, 65/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.61it/s, 66/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.38it/s, 67/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.46it/s, 68/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.34it/s, 69/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.54it/s, 70/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.19it/s, 71/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.56it/s, 72/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.58it/s, 73/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.42it/s, 74/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.41it/s, 75/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.50it/s, 76/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.26it/s, 77/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.28it/s, 78/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.22it/s, 79/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.34it/s, 80/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.21it/s, 81/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.19it/s, 82/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.33it/s, 83/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.23it/s, 84/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.30it/s, 85/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.50it/s, 86/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.22it/s, 87/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.35it/s, 88/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:16<00:00,  3.08it/s, 89/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:16<00:00,  3.11it/s, 90/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.30it/s, 91/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.27it/s, 92/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:16<00:00,  3.03it/s, 93/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.46it/s, 94/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:13<00:00,  3.69it/s, 95/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.58it/s, 96/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:13<00:00,  3.69it/s, 97/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:14<00:00,  3.61it/s, 98/194]\n",
      "100%|███████████████████████████████████| 51/51 [00:15<00:00,  3.34it/s, 99/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.52it/s, 100/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.42it/s, 101/194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.47it/s, 102/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.40it/s, 103/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.29it/s, 104/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.26it/s, 105/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.51it/s, 106/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.53it/s, 107/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.56it/s, 108/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.60it/s, 109/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.57it/s, 110/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.43it/s, 111/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.41it/s, 112/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.63it/s, 113/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.53it/s, 114/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.55it/s, 115/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.69it/s, 116/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.74it/s, 117/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.68it/s, 118/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.68it/s, 119/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.45it/s, 120/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.59it/s, 121/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.34it/s, 122/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.52it/s, 123/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.28it/s, 124/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.28it/s, 125/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.54it/s, 126/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.42it/s, 127/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.64it/s, 128/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.81it/s, 129/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.47it/s, 130/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.68it/s, 131/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.65it/s, 132/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.68it/s, 133/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.78it/s, 134/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.79it/s, 135/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.73it/s, 136/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.54it/s, 137/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.64it/s, 138/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.63it/s, 139/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.74it/s, 140/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.80it/s, 141/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.42it/s, 142/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.81it/s, 143/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.51it/s, 144/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.66it/s, 145/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.57it/s, 146/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.56it/s, 147/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.56it/s, 148/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.70it/s, 149/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.53it/s, 150/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.70it/s, 151/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.77it/s, 152/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.67it/s, 153/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.52it/s, 154/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.42it/s, 155/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:15<00:00,  3.25it/s, 156/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.46it/s, 157/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.51it/s, 158/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.66it/s, 159/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.75it/s, 160/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:13<00:00,  3.65it/s, 161/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.63it/s, 162/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.55it/s, 163/194]\n",
      "100%|██████████████████████████████████| 51/51 [00:14<00:00,  3.61it/s, 164/194]\n",
      " 78%|██████████████████████████▋       | 40/51 [00:10<00:03,  3.67it/s, 165/194]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'_SA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tf/31f0rc1x5k50qxxnbl8gjc1c0000gn/T/ipykernel_82178/3817425047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'negative'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotion_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_file_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'02'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0memotion\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'neutral'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '_SA'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the audio files to melspectrograms.\n",
    "counts = {}\n",
    "fileLoc=1\n",
    "for path in result:\n",
    "    files = tqdm(path)\n",
    "    for audio_file_path in files:\n",
    "        files.set_postfix_str(f\"{fileLoc}/{len(result)} \")\n",
    "        \n",
    "        em = audio_file_path[-18:-16]\n",
    "        \n",
    "        emotion = ''\n",
    "        \n",
    "        if em in ('01','02'):\n",
    "            emotion =  'neutral'\n",
    "        elif em in ('03','08'):\n",
    "            emotion = 'positive'\n",
    "        elif em in ('04','05','06','07'):\n",
    "            emotion = 'negative'\n",
    "        else:\n",
    "            second_underscore = audio_file_path.find('_', audio_file_path.find('_') + 1)\n",
    "            em = emotion_map[audio_file_path[second_underscore+1:second_underscore+4]]\n",
    "            if em in ('01','02'):\n",
    "                emotion =  'neutral'\n",
    "            elif em in ('03','08'):\n",
    "                emotion = 'positive'\n",
    "            elif em in ('04','05','06','07'):\n",
    "                emotion = 'negative'\n",
    "            \n",
    "        \n",
    "        count = counts.get(emotion, 1)\n",
    "                \n",
    "        p = os.path.join(f\"{DATASET}{emotion}\", f\"{emotion}{str(count).zfill(6)}_{dicts[em]}.jpg\")        \n",
    "        \n",
    "        counts[emotion] = count + 1\n",
    "        \n",
    "        convert_audio_to_melspectrogram(audio_file_path, p)\n",
    "    fileLoc+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73106ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2d119e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ./cremad/AudioWAV/1039_IWW_ANG_XX.wav ANG\n",
      "2 ./cremad/AudioWAV/1064_ITH_FEA_XX.wav FEA\n",
      "3 ./cremad/AudioWAV/1071_ITH_FEA_XX.wav FEA\n",
      "4 ./cremad/AudioWAV/1074_DFA_DIS_XX.wav DIS\n",
      "5 ./cremad/AudioWAV/1045_ITH_HAP_XX.wav HAP\n",
      "6 ./cremad/AudioWAV/1050_ITH_HAP_XX.wav HAP\n",
      "7 ./cremad/AudioWAV/1061_DFA_DIS_XX.wav DIS\n",
      "8 ./cremad/AudioWAV/1063_ITH_SAD_XX.wav SAD\n",
      "9 ./cremad/AudioWAV/1076_ITH_SAD_XX.wav SAD\n",
      "10 ./cremad/AudioWAV/1070_IEO_NEU_XX.wav NEU\n",
      "11 ./cremad/AudioWAV/1065_IEO_NEU_XX.wav NEU\n",
      "12 ./cremad/AudioWAV/1088_TIE_FEA_XX.wav FEA\n",
      "13 ./cremad/AudioWAV/1080_IWW_HAP_XX.wav HAP\n",
      "14 ./cremad/AudioWAV/1018_WSI_FEA_XX.wav FEA\n",
      "15 ./cremad/AudioWAV/1039_WSI_HAP_XX.wav HAP\n",
      "16 ./cremad/AudioWAV/1049_IEO_FEA_LO.wav FEA\n",
      "17 ./cremad/AudioWAV/1068_IEO_HAP_LO.wav HAP\n",
      "18 ./cremad/AudioWAV/1027_IWW_DIS_XX.wav DIS\n",
      "19 ./cremad/AudioWAV/1032_IWW_DIS_XX.wav DIS\n",
      "20 ./cremad/AudioWAV/1028_DFA_NEU_XX.wav NEU\n",
      "21 ./cremad/AudioWAV/1084_IWW_NEU_XX.wav NEU\n",
      "22 ./cremad/AudioWAV/1091_IWW_NEU_XX.wav NEU\n",
      "23 ./cremad/AudioWAV/1028_WSI_NEU_XX.wav NEU\n",
      "24 ./cremad/AudioWAV/1018_DFA_FEA_XX.wav FEA\n",
      "25 ./cremad/AudioWAV/1039_DFA_HAP_XX.wav HAP\n",
      "26 ./cremad/AudioWAV/1008_ITH_DIS_XX.wav DIS\n",
      "27 ./cremad/AudioWAV/1089_ITH_SAD_XX.wav SAD\n",
      "28 ./cremad/AudioWAV/1090_IOM_HAP_XX.wav HAP\n",
      "29 ./cremad/AudioWAV/1068_TSI_HAP_XX.wav HAP\n",
      "30 ./cremad/AudioWAV/1085_IOM_HAP_XX.wav HAP\n",
      "31 ./cremad/AudioWAV/1079_IEO_SAD_HI.wav SAD\n",
      "32 ./cremad/AudioWAV/1049_TSI_FEA_XX.wav FEA\n",
      "33 ./cremad/AudioWAV/1059_TAI_HAP_XX.wav HAP\n",
      "34 ./cremad/AudioWAV/1068_IEO_SAD_MD.wav SAD\n",
      "35 ./cremad/AudioWAV/1078_TAI_FEA_XX.wav FEA\n",
      "36 ./cremad/AudioWAV/1029_IWL_SAD_XX.wav SAD\n",
      "37 ./cremad/AudioWAV/1066_ITS_ANG_XX.wav ANG\n",
      "38 ./cremad/AudioWAV/1073_ITS_ANG_XX.wav ANG\n",
      "39 ./cremad/AudioWAV/1037_IOM_DIS_XX.wav DIS\n",
      "40 ./cremad/AudioWAV/1022_IOM_DIS_XX.wav DIS\n",
      "41 ./cremad/AudioWAV/1040_ITH_SAD_X.wav SAD\n",
      "42 ./cremad/AudioWAV/1024_ITS_NEU_XX.wav NEU\n",
      "43 ./cremad/AudioWAV/1031_ITS_NEU_XX.wav NEU\n",
      "44 ./cremad/AudioWAV/1081_IOM_NEU_XX.wav NEU\n",
      "45 ./cremad/AudioWAV/1079_TSI_NEU_XX.wav NEU\n",
      "46 ./cremad/AudioWAV/1087_ITS_DIS_XX.wav DIS\n",
      "47 ./cremad/AudioWAV/1083_MTI_FEA_XX.wav FEA\n",
      "48 ./cremad/AudioWAV/1006_ITS_SAD_XX.wav SAD\n",
      "49 ./cremad/AudioWAV/1048_TAI_NEU_XX.wav NEU\n",
      "50 ./cremad/AudioWAV/1013_ITS_SAD_XX.wav SAD\n",
      "51 ./cremad/AudioWAV/1019_IEO_ANG_HI.wav ANG\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "count = 1\n",
    "for i in result[164]:\n",
    "    second_underscore = i.find('_', i.find('_') + 1)\n",
    "\n",
    "    print(count, i, i[second_underscore+1:second_underscore+4])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "fs=44100\n",
    "seconds=3\n",
    "dtype = 'int16'\n",
    "mic = int(input(f'Of the following list of devices, select which one to use as your microphone:\\n{sd.query_devices()}\\n>>>'))\n",
    "count = 1\n",
    "\n",
    "while true:\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    \n",
    "    checkEmotion(count,mic, fs, seconds, dtype)\n",
    "    \n",
    "    cont = input(\"\\nContinue? (Y/N): \")\n",
    "    \n",
    "    if cont == 'Y' or cont == 'y':\n",
    "        count+=1\n",
    "        continue\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b0344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f81527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6493d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''loss_functions = [CrossEntropyLossFlat(), LabelSmoothingCrossEntropy(),\n",
    "                  FocalLossFlat()]\n",
    "loss_functions1 = [\"CrossEntropyLossFlat\", \"LabelSmoothingCrossEntropy\",\n",
    "                  \"FocalLossFlat\"]\n",
    "train_size = [0.2, 0.4, 0.6]\n",
    "\n",
    "for LF in range(0,3):\n",
    "    for TS in range(0,3):\n",
    "        print(f\"___________{loss_functions1[LF]} ... {train_size[TS]}___________\")\n",
    "        dls = ImageDataLoaders.from_folder(train_path, valid_pct=train_size[TS], seed=5, num_workers=0)\n",
    "        print(f\"validation: {len(dls.valid_ds.items[:])}  |  training set: {len(dls.train_ds.items[:])}\")\n",
    "\n",
    "        learn = vision_learner(dls, models.resnet34, loss_func=loss_functions[LF], metrics=accuracy)\n",
    "        lr_min, lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))\n",
    "        print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")\n",
    "\n",
    "        learn.fit(10, float(f\"{lr_steep:.2e}\"))\n",
    "        #interp = ClassificationInterpretation.from_learner(learn)\n",
    "        #losses,idxs = interp.top_losses()\n",
    "        #len(dls.valid_ds)==len(losses)==len(idxs)\n",
    "\n",
    "        #interp.plot_confusion_matrix(figsize=(8,8), dpi=90)\n",
    "\n",
    "        #interp.plot_top_losses(2, figsize=(10,11))\n",
    "        \n",
    "        print(\"\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1c051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d832f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59833a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204665bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9ef5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1379d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path('./Categorical_Dataset').with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047816c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = list(data_dir.glob('angry/*'))\n",
    "PIL.Image.open(str(anger[0]))\n",
    "PIL.Image.open(str(anger[1]))\n",
    "\n",
    "calm = list(data_dir.glob('calm/*'))\n",
    "PIL.Image.open(str(calm[0]))\n",
    "PIL.Image.open(str(calm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 240\n",
    "img_width = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7515319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58923e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56356651",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19434a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a906337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e322b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df52b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c07dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(val_ds)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = []\n",
    "for images, labels in val_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae317de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fight overfitting by using data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bb02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc958c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c6310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilizing Dropout\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da74d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca42f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e48554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions from the model\n",
    "predictions = model.predict(val_ds)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = []\n",
    "for images, labels in val_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b757c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = './DATASET/angry/angry000001.jpg'\n",
    "#file_path = tf.keras.utils.get_file('thingo', origin=location)\n",
    "\n",
    "#img = pathlib.Path('./DATASET/angry/angry000001.jpg')\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "   location, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "\n",
    "\n",
    "sorted_predictions = np.argsort(score)[::-1]\n",
    "\n",
    "# Take the top five predictions.\n",
    "top_predictions = sorted_predictions[:5]\n",
    "\n",
    "# Print the top five predictions.\n",
    "for i in range(len(top_predictions)):\n",
    "    print(\n",
    "        \"The image most likely belongs to {} with a {:.4f} percent confidence.\"\n",
    "        .format(class_names[top_predictions[i]], 100 * score[top_predictions[i]])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
